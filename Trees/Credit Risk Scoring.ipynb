{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5b85f44",
   "metadata": {},
   "source": [
    "## Decision Trees and Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b186154",
   "metadata": {},
   "source": [
    "In this project, we'll learn trees usind <b> Decision Tree</b> and <b>Ensemble learning</b>.\n",
    "\n",
    "The project is <b>Credit Risk Score</b> for loan applicants using using <b>CreditScoring.csv</b> dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77763706",
   "metadata": {},
   "source": [
    "## Data Preparation and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa13d26",
   "metadata": {},
   "source": [
    "- Loading the dataset\n",
    "- Re-encoding the categorical variables\n",
    "- Doing the train/validation/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4491283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0372b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"CreditScoring.csv\")\n",
    "df = pd.DataFrame(dataset)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccec71db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da520e6",
   "metadata": {},
   "source": [
    "There are categorical variables that are in numerical format that should be converted back to categorical for easy understanding. They include <b> status, home, marital, Recored and Job.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3d1a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start with status\n",
    "status_values = {\n",
    "    1: \"ok\",\n",
    "    2: \"default\",\n",
    "    0: \"unk\"\n",
    "}\n",
    "df.status = df.status.map(status_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e252ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for all other categorical features\n",
    "home_values = {\n",
    "    1: 'rent',\n",
    "    2: 'owner',\n",
    "    3: 'private',\n",
    "    4: 'ignore',\n",
    "    5: 'parents',\n",
    "    6: 'other',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.home = df.home.map(home_values)\n",
    "\n",
    "marital_values = {\n",
    "    1: 'single',\n",
    "    2: 'married',\n",
    "    3: 'widow',\n",
    "    4: 'separated',\n",
    "    5: 'divorced',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.marital = df.marital.map(marital_values)\n",
    "\n",
    "records_values = {\n",
    "    1: 'no',\n",
    "    2: 'yes',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.records = df.records.map(records_values)\n",
    "\n",
    "job_values = {\n",
    "    1: 'fixed',\n",
    "    2: 'partime',\n",
    "    3: 'freelance',\n",
    "    4: 'others',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.job = df.job.map(job_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3934d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cb9f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713bdce3",
   "metadata": {},
   "source": [
    "From statistical results above, some features have <b>99999999.0</b>for Max values which means that there are <b> missing values</b>. We'll handle them next "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a785f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace those 99999999.0 with nan\n",
    "for c in [\"income\", \"assets\", \"debt\"]:\n",
    "    df[c] = df[c].replace(to_replace=99999999, value=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1418822",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe44bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also remove the unkown value of status so that we only remain with OK and Default\n",
    "df = df[df.status != \"unk\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2715b0",
   "metadata": {},
   "source": [
    "Next we split the data frame in <b> train, validation, test</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599842b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=11)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f28c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680ab4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train), len(df_val), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our target variable as we convert the values from categorical format to numerical format\n",
    "y_train = (df_train.status == \"default\").astype(\"int\").values\n",
    "y_val = (df_val.status == \"default\").astype(\"int\").values\n",
    "y_test = (df_test.status == \"default\").astype(\"int\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we remove the target variables from the rest so that they are not accidentally used as X\n",
    "del df_train[\"status\"]\n",
    "del df_val[\"status\"]\n",
    "del df_test[\"status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1245fafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9f0290",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7ff662",
   "metadata": {},
   "source": [
    "- How a decision tree looks like\n",
    "- Training a decision tree\n",
    "- Overfitting\n",
    "- Controling the size of a tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97697be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple decision tree using if else statement\n",
    "def assess_risk(client):\n",
    "    if client[\"records\"] == \"yes\":\n",
    "        if client[\"job\"] == \"parttime\":\n",
    "            return \"default\"\n",
    "        else:\n",
    "            return \"ok\"\n",
    "    else:\n",
    "        if client[\"assets\"] > 6000:\n",
    "            return \"ok\"\n",
    "        else:\n",
    "            return \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23c35f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test the decision tree above\n",
    "xi = df_train.iloc[0].to_dict()\n",
    "xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd9c1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_risk(xi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a07913",
   "metadata": {},
   "source": [
    "And it works well given that the client's job is Freelance and the assests are 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab01d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's train using sklean's DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db6d75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the train data frame into dictionaries as we fill missing values with zeros\n",
    "train_dicts = df_train.fillna(0).to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e196e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle categorical variables\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train = dv.fit_transform(train_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311106b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check feature names\n",
    "dv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835d3ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now train the DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d196e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model using validation dataset\n",
    "val_dicts = df_val.fillna(0).to_dict(orient=\"records\")\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9676e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt.predict_proba(X_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a9e98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the roc auc of the model\n",
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68442dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC of the training dataset\n",
    "y_pred = dt.predict_proba(X_train)[:, 1]\n",
    "roc_auc_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f142cc53",
   "metadata": {},
   "source": [
    "Given that the model's <b>ROC AUC score</b> in validation set is 0.65 and that of train dataset is 1.0, it suggests that there is a problem of overfitting.\n",
    "\n",
    "Now this might be due to the model learning too deep to an extent it memorizes specific information about clients hence fail to <b>generalize</b>.\n",
    "\n",
    "We can try to prevent this by restricting the level as to which the model can reach when it is training as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b58aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new model which only goes as far as to the depth of 3\n",
    "dt = DecisionTreeClassifier(max_depth=3)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9f7832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc when the tree is restricted to 3 levels\n",
    "y_pred = dt.predict_proba(X_train)[:, 1]\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print(\"train: \", auc)\n",
    "\n",
    "y_pred = dt.predict_proba(X_val)[:, 1]\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "print(\"val: \", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46184cee",
   "metadata": {},
   "source": [
    "As seen above, the model is better than when it was before restricting to 3 levels, however if it is restricted too much, the results will be even worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b510517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets visualize the rules the tree learned from\n",
    "from sklearn.tree import export_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ab1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(export_text(dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c346a34",
   "metadata": {},
   "source": [
    "## Decision tree learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f16c49",
   "metadata": {},
   "source": [
    "- Finding the best split for one column\n",
    "- Finding the best split for the entire dataset\n",
    "- Stopping criteria\n",
    "- Decision tree learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c956eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a small dataset for demonstration\n",
    "data = [\n",
    "    [8000, \"default\"],\n",
    "    [2000, \"default\"],\n",
    "    [0, \"default\"],\n",
    "    [5000, \"ok\"],\n",
    "    [5000, \"ok\"],\n",
    "    [4000, \"ok\"],\n",
    "    [9000, \"ok\"],\n",
    "    [3000, \"default\"],\n",
    "]\n",
    "\n",
    "df_example = pd.DataFrame(data, columns=[\"assets\", \"status\"])\n",
    "df_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c593d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_example.sort_values(\"assets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f2a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# potential thresholds for splitting the dataframe\n",
    "Ts = [0, 2000, 3000, 4000, 5000, 8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155f3e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af1111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate splitting using the various splits\n",
    "for T in Ts:\n",
    "    print(T)\n",
    "    df_left = df_example[df_example.assets <= T]\n",
    "    df_right = df_example[df_example.assets > T]\n",
    "    \n",
    "    display(df_left)\n",
    "    print(df_left.status.value_counts(normalize=True))\n",
    "    display(df_right)\n",
    "    print(df_right.status.value_counts(normalize=True))\n",
    "\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c0c227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset with more than one feature\n",
    "data = [\n",
    "    [8000, 3000, \"default\"],\n",
    "    [2000, 1000, \"default\"],\n",
    "    [0, 1000, \"default\"],\n",
    "    [5000, 1000, \"ok\"],\n",
    "    [5000, 1000, \"ok\"],\n",
    "    [4000, 1000, \"ok\"],\n",
    "    [9000, 500, \"ok\"],\n",
    "    [3000, 2000, \"default\"],\n",
    "]\n",
    "\n",
    "df_example = pd.DataFrame(data, columns=[\"assets\",\"debt\", \"status\"])\n",
    "df_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facd10ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_example.sort_values(\"debt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c82e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generalized potential thresholds for splitting the dataset with more than one feature\n",
    "thresholds = {\n",
    "    \"assets\": [0, 2000, 3000, 4000, 5000, 8000],\n",
    "    \"debt\": [500, 1000, 2000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a915d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, Ts in thresholds.items():\n",
    "    print(\"##########\")\n",
    "    print(feature)\n",
    "    for T in Ts:\n",
    "        print(T)\n",
    "        df_left = df_example[df_example[feature] <= T]\n",
    "        df_right = df_example[df_example[feature] > T]\n",
    "\n",
    "        display(df_left)\n",
    "        print(df_left.status.value_counts(normalize=True))\n",
    "        display(df_right)\n",
    "        print(df_right.status.value_counts(normalize=True))\n",
    "\n",
    "\n",
    "        print()\n",
    "    print(\"##########\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81083a7",
   "metadata": {},
   "source": [
    "## Decision Trees Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40d669d",
   "metadata": {},
   "source": [
    "- Selecting max_depth\n",
    "- selecting min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef8a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DecisionTree model based on different set depths as you calculate auc of each\n",
    "for d in [1, 2, 3, 4, 5, 6, 10, 15, 20, None]:\n",
    "    dt = DecisionTreeClassifier(max_depth=d)\n",
    "    dt.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = dt.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    \n",
    "    print(\"%4s -> %.3f\" % (d, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27c44ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing min_samples_leaf to the model\n",
    "scores = []\n",
    "\n",
    "for d in [4, 5, 6, 7, 10, 15, 20]:\n",
    "    for s in [1, 2, 5, 10, 15, 20, 100, 200, 500]:\n",
    "        dt = DecisionTreeClassifier(max_depth=d, min_samples_leaf=s)\n",
    "        dt.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = dt.predict_proba(X_val)[:, 1]\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "        scores.append((d, s, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9cb71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data frame for the scores\n",
    "columns = [\"max_depth\", \"min_samples_leaf\", \"auc\"]\n",
    "df_scores = pd.DataFrame(scores, columns=columns)\n",
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1670648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.sort_values(by=\"auc\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73742650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivote the data frame to visualize it well\n",
    "df_scores_pivot = df_scores.pivot(index=\"min_samples_leaf\",\n",
    "                                 columns=[\"max_depth\"], values=[\"auc\"])\n",
    "df_scores_pivot.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adec37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize it as a heatmap\n",
    "sns.heatmap(df_scores_pivot, annot=True, fmt=\".3f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb6a192",
   "metadata": {},
   "source": [
    "Using a max_depth of 6 and min_samples_leaf of 15 seems to work well. Let's implement it to a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ebcc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=6, min_samples_leaf=15)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06978d0a",
   "metadata": {},
   "source": [
    "## Ensemble Learning and Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50406faf",
   "metadata": {},
   "source": [
    "- Board experts\n",
    "- Ensembling models\n",
    "- Random forest - ensembling decision trees\n",
    "- Tuning random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b71e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import RandomForestClassifier from sklearns ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f55328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a random forest model\n",
    "rf = RandomForestClassifier(n_estimators=10, random_state=1)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3060f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability predict based on validation set\n",
    "y_pred = rf.predict_proba(X_val)[:, 1]\n",
    "# auc score\n",
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06799cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine what happend when the number of estimators changes\n",
    "scores = []\n",
    "\n",
    "for n in range(10, 201, 10):\n",
    "    rf = RandomForestClassifier(n_estimators=n, random_state=1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    scores.append((n, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1636418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a scores data frame for easy visualization\n",
    "df_scores = pd.DataFrame(scores, columns=[\"n_estimators\", \"auc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29946d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8e75b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the graph of estimators and auc score to see the number of trees necessay for the model\n",
    "plt.plot(df_scores.n_estimators, df_scores.auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d010b7",
   "metadata": {},
   "source": [
    "The plot above indicates that the model's score increases up until when it reaches 50 trees, it then remains to be stagnant for the rest number of trees.\n",
    "\n",
    "This then implies that the required number of trees for this model is 50, the rest don't contribute much to the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c6cf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's tune the random forest by training it using different depths for the trees\n",
    "# using max_depth\n",
    "scores = []\n",
    "\n",
    "for d in [5, 10, 15]:\n",
    "    for n in range(10, 201, 10):\n",
    "        rf = RandomForestClassifier(n_estimators=n, \n",
    "                                    max_depth=d, \n",
    "                                    random_state=1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict_proba(X_val)[:, 1]\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        scores.append((d, n, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e53f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_score dataframe with max_depth features\n",
    "columns = [\"max_depth\", \"n_estimators\", \"auc\"]\n",
    "df_scores = pd.DataFrame(scores, columns=columns)\n",
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9abd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A plot of the different depths performances\n",
    "for d in [5, 10, 15]:\n",
    "    df_subset = df_scores[df_scores.max_depth == d]\n",
    "    plt.plot(df_subset.n_estimators, df_subset.auc,\n",
    "            label=\"max_depth=%d\" % d)\n",
    "    \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a687161e",
   "metadata": {},
   "source": [
    "From the plot above, the best size of depth is 10.\n",
    "\n",
    "Now let's find out that of min_sample_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8644ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d17d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune it further as we find out the best min_sample_leaf\n",
    "scores = []\n",
    "\n",
    "for s in [1, 3, 5, 10, 50]:\n",
    "    for n in range(10, 201, 10):\n",
    "        rf = RandomForestClassifier(n_estimators=n, \n",
    "                                    max_depth=max_depth,\n",
    "                                    min_samples_leaf=s,\n",
    "                                    random_state=1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict_proba(X_val)[:, 1]\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        scores.append((s, n, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b21d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"min_samples_leaf\", \"n_estimators\", \"auc\"]\n",
    "df_scores = pd.DataFrame(scores, columns=columns)\n",
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef06c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A plot of the different min_sample_leaf performances\n",
    "colors = [\"black\", \"blue\", \"orange\", \"red\", \"grey\"]\n",
    "min_samples_leaf_values = [1, 3, 5, 10, 50]\n",
    "for s, col in zip(min_samples_leaf_values, colors):\n",
    "    df_subset = df_scores[df_scores.min_samples_leaf == s]\n",
    "    plt.plot(df_subset.n_estimators, df_subset.auc, color=col,\n",
    "            label=\"min_samples_leaf=%s\" % s)\n",
    "    \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71758abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_leaf = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930a730a",
   "metadata": {},
   "source": [
    "Here our best min_sample_leaf is 3 and it works well at around 100 because beyond that the model is fairly stagnant.\n",
    "\n",
    "We'll now retrain the model using these two parameters, that is, max_depth of 10 and min_sample_leaf of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b7401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain the model\n",
    "rf = RandomForestClassifier(n_estimators=100, \n",
    "                            max_depth=max_depth,\n",
    "                            min_samples_leaf=min_samples_leaf,\n",
    "                            random_state=1,\n",
    "                            n_jobs=-1)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92afcd06",
   "metadata": {},
   "source": [
    "## Gradient boosting and XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd222067",
   "metadata": {},
   "source": [
    "- Gradient boosting vs Random Forest\n",
    "- Installing XGBoost\n",
    "- Training the first model\n",
    "- Performance monitoring\n",
    "- Parsing xgboost's monitoring output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f7a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39bf83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap the training dataset into a XGBoost's Dmatrix datamatrix for easy training with xgboost\n",
    "features = dv.get_feature_names_out()\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=features)\n",
    "dval = xgb.DMatrix(X_val, label=y_val, feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8a93b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "xgb_params = {\n",
    "    \"eta\": 0.3,\n",
    "    \"max_depth\": 6,\n",
    "    \"min_child_weight\": 1,\n",
    "    \n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"nthread\": 8,\n",
    "    \n",
    "    \"seed\": 1,\n",
    "    \"verbosity\": 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3773c130",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6911d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model based on the training data by creating a watchlist\n",
    "watchlist = [(dtrain, \"train\"), (dval, \"val\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6518c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.magic import register_line_magic\n",
    "\n",
    "def %%capture(code):\n",
    "    captured_output = None\n",
    "    try:\n",
    "        captured_output = eval(code)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return captured_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1db54ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain the xgboost model\n",
    "%%capture output\n",
    "xgb_params = {\n",
    "    \"eta\": 0.3,\n",
    "    \"max_depth\": 6,\n",
    "    \"min_child_weight\": 1,\n",
    "    \n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"nthread\": 8,\n",
    "    \n",
    "    \"seed\": 1,\n",
    "    \"verbosity\": 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain, \n",
    "                  evals=watchlist,\n",
    "                  verbose_eval= 5,\n",
    "                  num_boost_round=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4ad100",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = output.stdout\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a657d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the auc scores so that you can visualize them differently\n",
    "def parse_xgb_output(output):\n",
    "    results = []\n",
    "    \n",
    "    for line in output.stdout.strip().split(\"\\n\"):\n",
    "        it_line, train_line, val_line = line.split(\"\\t\")\n",
    "        \n",
    "        it = int(it_line.strip(\"[]\"))\n",
    "        train = float(train_line.split(\":\")[1])\n",
    "        val = float(val_line.split(\":\")[1])\n",
    "        \n",
    "        results.append((it, train_line, val))\n",
    "        \n",
    "    columns = [\"num_iter\", \"train_auc\", \"val_auc\"]\n",
    "    df_results = pd.DataFrame(results, columns=columns)\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf16224",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score = parse_xgb_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9cb5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the score dataframe\n",
    "plt.plot(df_score.num_iter, df_score.train_auc, label=\"train\")\n",
    "plt.plot(df_score.num_iter, df_score.val_auc, label=\"val\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7575247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
